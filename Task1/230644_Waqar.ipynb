{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Regression**\n",
        "We will use Linear regression for predicting house prices\n",
        "\n",
        "We are using a Kaggle dataset- https://www.kaggle.com/harlfoxem/housesalesprediction"
      ],
      "metadata": {
        "id": "FSRalact4xj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets import required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "J8MRCcJY2btt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset Preparation**"
      ],
      "metadata": {
        "id": "1MzAhMmE6UHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this cell for loading dataset in a pandas dataframe\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct' -O Linear_regression_dataset\n",
        "\n",
        "data_df = pd.read_csv(\"Linear_regression_dataset\")"
      ],
      "metadata": {
        "id": "LiWI-2py554R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713ba29b-c31e-46fd-ba04-1cf17e6a6608"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-24 10:10:18--  https://docs.google.com/uc?export=download&id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.101, 74.125.195.102, 74.125.195.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct&export=download [following]\n",
            "--2024-05-24 10:10:18--  https://drive.usercontent.google.com/download?id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.203.132, 2607:f8b0:400e:c05::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2515206 (2.4M) [application/octet-stream]\n",
            "Saving to: ‘Linear_regression_dataset’\n",
            "\n",
            "Linear_regression_d 100%[===================>]   2.40M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-05-24 10:10:19 (94.8 MB/s) - ‘Linear_regression_dataset’ saved [2515206/2515206]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets have a quick Look at dataset\n",
        "\n",
        "print(\"(No of rows, No of Columns) = \",data_df.shape)\n",
        "data_df.head()"
      ],
      "metadata": {
        "id": "TAodxbYX7AKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "d538fc7f-b41d-440b-a564-5d9f9c42e4bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(No of rows, No of Columns) =  (21613, 21)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
              "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
              "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
              "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
              "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
              "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
              "\n",
              "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
              "0      5650     1.0           0     0  ...      7        1180              0   \n",
              "1      7242     2.0           0     0  ...      7        2170            400   \n",
              "2     10000     1.0           0     0  ...      6         770              0   \n",
              "3      5000     1.0           0     0  ...      7        1050            910   \n",
              "4      8080     1.0           0     0  ...      8        1680              0   \n",
              "\n",
              "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
              "0      1955             0    98178  47.5112 -122.257           1340   \n",
              "1      1951          1991    98125  47.7210 -122.319           1690   \n",
              "2      1933             0    98028  47.7379 -122.233           2720   \n",
              "3      1965             0    98136  47.5208 -122.393           1360   \n",
              "4      1987             0    98074  47.6168 -122.045           1800   \n",
              "\n",
              "   sqft_lot15  \n",
              "0        5650  \n",
              "1        7639  \n",
              "2        8062  \n",
              "3        5000  \n",
              "4        7503  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e80d7279-2623-4ffe-9700-c5d1a9afe891\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>...</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80d7279-2623-4ffe-9700-c5d1a9afe891')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e80d7279-2623-4ffe-9700-c5d1a9afe891 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e80d7279-2623-4ffe-9700-c5d1a9afe891');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2316d4fd-f843-4380-9fbe-faf85e3f60b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2316d4fd-f843-4380-9fbe-faf85e3f60b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2316d4fd-f843-4380-9fbe-faf85e3f60b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So there are **19** features (of course we will not use id as feature :) ), and 1 variable to predict(price)\n",
        "\n",
        "But note that the **date** column contain strings so first we will remove T00.. part from it and than convert it to numpy array."
      ],
      "metadata": {
        "id": "gsJaooGZ7pUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['date'] = data_df['date'].str.replace('T000000', '')\n",
        "\n",
        "\n",
        "data_df['date'] = pd.to_datetime(data_df['date']).dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "data_df['date'] = pd.to_datetime(data_df['date']).dt.strftime('%Y%m%d').astype(int)                                       # Remove T000000 part from data column. Hint: search about .str.replace() method. :)\n",
        "\n",
        "data_array = data_df.drop(columns=['id']).values                                              # Create a numpy array which does not have \"id\" field\n",
        "assert (data_array.shape == (21613,20))\n",
        "\n",
        "data_df.head()"
      ],
      "metadata": {
        "id": "FNFNf3jT7oxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7f1320dd-e20e-4581-c87f-e722881749c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id      date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
              "0  7129300520  19700101  221900.0         3       1.00         1180      5650   \n",
              "1  6414100192  19700101  538000.0         3       2.25         2570      7242   \n",
              "2  5631500400  19700101  180000.0         2       1.00          770     10000   \n",
              "3  2487200875  19700101  604000.0         4       3.00         1960      5000   \n",
              "4  1954400510  19700101  510000.0         3       2.00         1680      8080   \n",
              "\n",
              "   floors  waterfront  view  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
              "0     1.0           0     0  ...      7        1180              0      1955   \n",
              "1     2.0           0     0  ...      7        2170            400      1951   \n",
              "2     1.0           0     0  ...      6         770              0      1933   \n",
              "3     1.0           0     0  ...      7        1050            910      1965   \n",
              "4     1.0           0     0  ...      8        1680              0      1987   \n",
              "\n",
              "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
              "0             0    98178  47.5112 -122.257           1340        5650  \n",
              "1          1991    98125  47.7210 -122.319           1690        7639  \n",
              "2             0    98028  47.7379 -122.233           2720        8062  \n",
              "3             0    98136  47.5208 -122.393           1360        5000  \n",
              "4             0    98074  47.6168 -122.045           1800        7503  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e372bd9e-a1eb-4028-a9c4-5b96e3bd86d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>...</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>19700101</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>19700101</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>19700101</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>19700101</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>19700101</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e372bd9e-a1eb-4028-a9c4-5b96e3bd86d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e372bd9e-a1eb-4028-a9c4-5b96e3bd86d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e372bd9e-a1eb-4028-a9c4-5b96e3bd86d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cb9b776-0333-4053-aad7-7501ccba9c88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cb9b776-0333-4053-aad7-7501ccba9c88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cb9b776-0333-4053-aad7-7501ccba9c88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the next task is **normalization**.\n",
        "\n",
        "We will scale each column of dataset by x -> (x-u)/s\n",
        "\n",
        "where u is mean(x), and s is standard deviation of u"
      ],
      "metadata": {
        "id": "xsBZxZ4x-oBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(data_array, axis=0)                                 # this should be an array, each entry should be mean of a column\n",
        "sd = np.std(data_array, axis=0)                                    # this should be an array, each entry should be standard deviation of a column\n",
        "\n",
        "data_array_norm = (data_array - mean)/sd\n",
        "\n",
        "print(data_array_norm.shape)"
      ],
      "metadata": {
        "id": "u7GZV-0T_zCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de553f37-bea3-4e45-b3a8-456e8d0f11b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21613, 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f1f57a595d31>:4: RuntimeWarning: divide by zero encountered in divide\n",
            "  data_array_norm = (data_array - mean)/sd\n",
            "<ipython-input-11-f1f57a595d31>:4: RuntimeWarning: invalid value encountered in divide\n",
            "  data_array_norm = (data_array - mean)/sd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is to make train and test dataset and to create seperate vector for price"
      ],
      "metadata": {
        "id": "VCQTrNIgAlPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data_df['price'].values                                                                                                         # extract the price column from data\n",
        "\n",
        "x_array_norm = np.delete(data_array_norm, 2, axis=1)                                                                                                    # delete the price column from data_array_norm. Hint: use np.delete()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_array_norm,labels,test_size=0.2,random_state=42,shuffle=True)    # splitting data into test and train set.\n",
        "\n",
        "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "dJyX5QOFBRg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb83364-f41c-4062-d3bd-166cd60e3880"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17290, 19) (4323, 19) (17290,) (4323,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loss and gradient descent**\n",
        "We will use mean squared error(MSE) as loss\n",
        "\n",
        "Use the gradient descent algorithm which you learned from tutorials\n",
        "\n",
        "Your task is to complete the following functions"
      ],
      "metadata": {
        "id": "iAdW-22ZDcdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_pred,y_true):\n",
        "  \"\"\"\n",
        "  input:\n",
        "  y_pred = [array] predicted value of y\n",
        "  y_true = [array] ground truth\n",
        "\n",
        "  output:\n",
        "  mse: [scalar] the MES loss\n",
        "  \"\"\"\n",
        "  mse = np.mean((y_true - y_pred) == 2)                     # fill code here\n",
        "\n",
        "  return mse"
      ],
      "metadata": {
        "id": "ufoIQOpeEFQx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y(x,a,b):\n",
        "  \"\"\"\n",
        "  This function should return predicted value of y = ax+b\n",
        "  input:\n",
        "  x: [array] the feature vector of shape (m,n)\n",
        "  a: [array] weights of shape (n,)\n",
        "  b: [scalar] bias\n",
        "\n",
        "  output:\n",
        "  y_pred: [array] predicted value of y of shape (m,)\n",
        "  \"\"\"\n",
        "\n",
        "  m,n = x.shape\n",
        "  y_pred  = np.dot(x, a) + b\n",
        "  # y_pred.astype(float)\n",
        "                   # fill code here\n",
        "\n",
        "  assert(y_pred.shape == (m,))\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "a6LogNz5E28X"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(x,a,b,y_true):\n",
        "  \"\"\"\n",
        "  This function shoud return gradient of loss\n",
        "  input:\n",
        "  x: [array] the feature vector of shape (m,n)\n",
        "  a: [array] weights of shape (n,)\n",
        "  b: [scalar] bias\n",
        "  y_true: [array] ground truth of shape (m,)\n",
        "\n",
        "  output:\n",
        "  grad: [tuple] a tuple (derivative with respect to a[array of shape(n,)], derivative with respect to b[scalar])\n",
        "  \"\"\"\n",
        "  m,n = x.shape\n",
        "  yp = y(x,a,b)\n",
        "  y_true = y_true.astype(float)\n",
        "  da = (2/m) * np.dot(x.T, (yp - y_true))              # write code to calculate derivative of loss with respect to a\n",
        "  db = (2/m) * np.sum(yp - y_true)           # write code to calculate derivative of loss with respect to b\n",
        "  # d=[1]*n\n",
        "  # for k in range(0,n,1):\n",
        "  #   d[k] = 2*np.mean(x[:,k]*np.subtract(yp,y_true))\n",
        "  # da = np.array(d)              # write code to calculate derivative of loss with respect to a\n",
        "  # db = 2*np.mean(np.subtract(yp,y_true))\n",
        "  assert(da.shape ==(n,))\n",
        "  return (da,db)"
      ],
      "metadata": {
        "id": "lYnPROu8Gxwi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x,y_true,learning_rate=0.01,epochs = 10):\n",
        "  \"\"\"\n",
        "  This function perfroms gradient descent and minimizes loss\n",
        "  input:\n",
        "  x: [array] the feature vector of shape (m,n)\n",
        "  y_true: [array] ground truth of shape (m,)\n",
        "\n",
        "  output:\n",
        "  loss: [array] of size (epochs,)\n",
        "  weights: [tuple] (a,b)\n",
        "  \"\"\"\n",
        "  m,n = x.shape\n",
        "  loss_mse = []                                 # initialize empty list to store loss\n",
        "  a =  np.zeros(n)                                      # initialize a- weights and b- bias\n",
        "  b = 0.0\n",
        "\n",
        "  for i in range(epochs):\n",
        "      # calculate derivative using gradient() function\n",
        "    da, db = gradient(x, a, b, y_true)\n",
        "    # apply gradient descent now to update a and b\n",
        "    a -= learning_rate * da\n",
        "    b -= learning_rate * db\n",
        "    y_pred = y(x, a, b)\n",
        "    l_mse = loss(y(x,a,b),y_true)                               # calculate loss at this point\n",
        "    loss_mse.append(l_mse)\n",
        "\n",
        "  # m,n = x.shape\n",
        "  # loss_mse = []\n",
        "  # v = [0]*n                                 # initialize empty list to store loss\n",
        "  # a = np.array(v)\n",
        "  # n, = a.shape                              # initialize a- weights and b- bias\n",
        "  # b = 0\n",
        "\n",
        "  # for i in range(epochs):\n",
        "  #   # calculate derivative using gradient() function\n",
        "  #   # apply gradient descent now to update a and b\n",
        "  #   for j in range(int(n)):\n",
        "  #     a[j] = a[j] - learning_rate*gradient(x,a,b,y_true)[0][j]\n",
        "  #   b = b - learning_rate*gradient(x,a,b,y_true)[1]\n",
        "\n",
        "  #   l_mse = loss(y(x,a,b),y_true)                                # calculate loss at this point\n",
        "  #   loss_mse.append(l_mse)\n",
        "\n",
        "    print(\"Epoch \",i+1,\" Completed!\",\"loss = \",l_mse)\n",
        "\n",
        "  print(\"Training completed!!\")\n",
        "\n",
        "  assert(a.shape==(n,))\n",
        "\n",
        "  return (loss_mse,a,b)"
      ],
      "metadata": {
        "id": "km_z3ojKKQdj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "VsR5XLl_WVu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000             # tweak this!!!\n",
        "learn_rate = 0.01          # choose learning rate wisely otherwise loss may diverge!!\n",
        "\n",
        "train_loss,a,b = gradient_descent(x_train, y_train, learn_rate, epochs)"
      ],
      "metadata": {
        "id": "5A9mqkqLWU27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86be7204-234b-479c-8466-608302908f1e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1  Completed! loss =  0.0\n",
            "Epoch  2  Completed! loss =  0.0\n",
            "Epoch  3  Completed! loss =  0.0\n",
            "Epoch  4  Completed! loss =  0.0\n",
            "Epoch  5  Completed! loss =  0.0\n",
            "Epoch  6  Completed! loss =  0.0\n",
            "Epoch  7  Completed! loss =  0.0\n",
            "Epoch  8  Completed! loss =  0.0\n",
            "Epoch  9  Completed! loss =  0.0\n",
            "Epoch  10  Completed! loss =  0.0\n",
            "Epoch  11  Completed! loss =  0.0\n",
            "Epoch  12  Completed! loss =  0.0\n",
            "Epoch  13  Completed! loss =  0.0\n",
            "Epoch  14  Completed! loss =  0.0\n",
            "Epoch  15  Completed! loss =  0.0\n",
            "Epoch  16  Completed! loss =  0.0\n",
            "Epoch  17  Completed! loss =  0.0\n",
            "Epoch  18  Completed! loss =  0.0\n",
            "Epoch  19  Completed! loss =  0.0\n",
            "Epoch  20  Completed! loss =  0.0\n",
            "Epoch  21  Completed! loss =  0.0\n",
            "Epoch  22  Completed! loss =  0.0\n",
            "Epoch  23  Completed! loss =  0.0\n",
            "Epoch  24  Completed! loss =  0.0\n",
            "Epoch  25  Completed! loss =  0.0\n",
            "Epoch  26  Completed! loss =  0.0\n",
            "Epoch  27  Completed! loss =  0.0\n",
            "Epoch  28  Completed! loss =  0.0\n",
            "Epoch  29  Completed! loss =  0.0\n",
            "Epoch  30  Completed! loss =  0.0\n",
            "Epoch  31  Completed! loss =  0.0\n",
            "Epoch  32  Completed! loss =  0.0\n",
            "Epoch  33  Completed! loss =  0.0\n",
            "Epoch  34  Completed! loss =  0.0\n",
            "Epoch  35  Completed! loss =  0.0\n",
            "Epoch  36  Completed! loss =  0.0\n",
            "Epoch  37  Completed! loss =  0.0\n",
            "Epoch  38  Completed! loss =  0.0\n",
            "Epoch  39  Completed! loss =  0.0\n",
            "Epoch  40  Completed! loss =  0.0\n",
            "Epoch  41  Completed! loss =  0.0\n",
            "Epoch  42  Completed! loss =  0.0\n",
            "Epoch  43  Completed! loss =  0.0\n",
            "Epoch  44  Completed! loss =  0.0\n",
            "Epoch  45  Completed! loss =  0.0\n",
            "Epoch  46  Completed! loss =  0.0\n",
            "Epoch  47  Completed! loss =  0.0\n",
            "Epoch  48  Completed! loss =  0.0\n",
            "Epoch  49  Completed! loss =  0.0\n",
            "Epoch  50  Completed! loss =  0.0\n",
            "Epoch  51  Completed! loss =  0.0\n",
            "Epoch  52  Completed! loss =  0.0\n",
            "Epoch  53  Completed! loss =  0.0\n",
            "Epoch  54  Completed! loss =  0.0\n",
            "Epoch  55  Completed! loss =  0.0\n",
            "Epoch  56  Completed! loss =  0.0\n",
            "Epoch  57  Completed! loss =  0.0\n",
            "Epoch  58  Completed! loss =  0.0\n",
            "Epoch  59  Completed! loss =  0.0\n",
            "Epoch  60  Completed! loss =  0.0\n",
            "Epoch  61  Completed! loss =  0.0\n",
            "Epoch  62  Completed! loss =  0.0\n",
            "Epoch  63  Completed! loss =  0.0\n",
            "Epoch  64  Completed! loss =  0.0\n",
            "Epoch  65  Completed! loss =  0.0\n",
            "Epoch  66  Completed! loss =  0.0\n",
            "Epoch  67  Completed! loss =  0.0\n",
            "Epoch  68  Completed! loss =  0.0\n",
            "Epoch  69  Completed! loss =  0.0\n",
            "Epoch  70  Completed! loss =  0.0\n",
            "Epoch  71  Completed! loss =  0.0\n",
            "Epoch  72  Completed! loss =  0.0\n",
            "Epoch  73  Completed! loss =  0.0\n",
            "Epoch  74  Completed! loss =  0.0\n",
            "Epoch  75  Completed! loss =  0.0\n",
            "Epoch  76  Completed! loss =  0.0\n",
            "Epoch  77  Completed! loss =  0.0\n",
            "Epoch  78  Completed! loss =  0.0\n",
            "Epoch  79  Completed! loss =  0.0\n",
            "Epoch  80  Completed! loss =  0.0\n",
            "Epoch  81  Completed! loss =  0.0\n",
            "Epoch  82  Completed! loss =  0.0\n",
            "Epoch  83  Completed! loss =  0.0\n",
            "Epoch  84  Completed! loss =  0.0\n",
            "Epoch  85  Completed! loss =  0.0\n",
            "Epoch  86  Completed! loss =  0.0\n",
            "Epoch  87  Completed! loss =  0.0\n",
            "Epoch  88  Completed! loss =  0.0\n",
            "Epoch  89  Completed! loss =  0.0\n",
            "Epoch  90  Completed! loss =  0.0\n",
            "Epoch  91  Completed! loss =  0.0\n",
            "Epoch  92  Completed! loss =  0.0\n",
            "Epoch  93  Completed! loss =  0.0\n",
            "Epoch  94  Completed! loss =  0.0\n",
            "Epoch  95  Completed! loss =  0.0\n",
            "Epoch  96  Completed! loss =  0.0\n",
            "Epoch  97  Completed! loss =  0.0\n",
            "Epoch  98  Completed! loss =  0.0\n",
            "Epoch  99  Completed! loss =  0.0\n",
            "Epoch  100  Completed! loss =  0.0\n",
            "Epoch  101  Completed! loss =  0.0\n",
            "Epoch  102  Completed! loss =  0.0\n",
            "Epoch  103  Completed! loss =  0.0\n",
            "Epoch  104  Completed! loss =  0.0\n",
            "Epoch  105  Completed! loss =  0.0\n",
            "Epoch  106  Completed! loss =  0.0\n",
            "Epoch  107  Completed! loss =  0.0\n",
            "Epoch  108  Completed! loss =  0.0\n",
            "Epoch  109  Completed! loss =  0.0\n",
            "Epoch  110  Completed! loss =  0.0\n",
            "Epoch  111  Completed! loss =  0.0\n",
            "Epoch  112  Completed! loss =  0.0\n",
            "Epoch  113  Completed! loss =  0.0\n",
            "Epoch  114  Completed! loss =  0.0\n",
            "Epoch  115  Completed! loss =  0.0\n",
            "Epoch  116  Completed! loss =  0.0\n",
            "Epoch  117  Completed! loss =  0.0\n",
            "Epoch  118  Completed! loss =  0.0\n",
            "Epoch  119  Completed! loss =  0.0\n",
            "Epoch  120  Completed! loss =  0.0\n",
            "Epoch  121  Completed! loss =  0.0\n",
            "Epoch  122  Completed! loss =  0.0\n",
            "Epoch  123  Completed! loss =  0.0\n",
            "Epoch  124  Completed! loss =  0.0\n",
            "Epoch  125  Completed! loss =  0.0\n",
            "Epoch  126  Completed! loss =  0.0\n",
            "Epoch  127  Completed! loss =  0.0\n",
            "Epoch  128  Completed! loss =  0.0\n",
            "Epoch  129  Completed! loss =  0.0\n",
            "Epoch  130  Completed! loss =  0.0\n",
            "Epoch  131  Completed! loss =  0.0\n",
            "Epoch  132  Completed! loss =  0.0\n",
            "Epoch  133  Completed! loss =  0.0\n",
            "Epoch  134  Completed! loss =  0.0\n",
            "Epoch  135  Completed! loss =  0.0\n",
            "Epoch  136  Completed! loss =  0.0\n",
            "Epoch  137  Completed! loss =  0.0\n",
            "Epoch  138  Completed! loss =  0.0\n",
            "Epoch  139  Completed! loss =  0.0\n",
            "Epoch  140  Completed! loss =  0.0\n",
            "Epoch  141  Completed! loss =  0.0\n",
            "Epoch  142  Completed! loss =  0.0\n",
            "Epoch  143  Completed! loss =  0.0\n",
            "Epoch  144  Completed! loss =  0.0\n",
            "Epoch  145  Completed! loss =  0.0\n",
            "Epoch  146  Completed! loss =  0.0\n",
            "Epoch  147  Completed! loss =  0.0\n",
            "Epoch  148  Completed! loss =  0.0\n",
            "Epoch  149  Completed! loss =  0.0\n",
            "Epoch  150  Completed! loss =  0.0\n",
            "Epoch  151  Completed! loss =  0.0\n",
            "Epoch  152  Completed! loss =  0.0\n",
            "Epoch  153  Completed! loss =  0.0\n",
            "Epoch  154  Completed! loss =  0.0\n",
            "Epoch  155  Completed! loss =  0.0\n",
            "Epoch  156  Completed! loss =  0.0\n",
            "Epoch  157  Completed! loss =  0.0\n",
            "Epoch  158  Completed! loss =  0.0\n",
            "Epoch  159  Completed! loss =  0.0\n",
            "Epoch  160  Completed! loss =  0.0\n",
            "Epoch  161  Completed! loss =  0.0\n",
            "Epoch  162  Completed! loss =  0.0\n",
            "Epoch  163  Completed! loss =  0.0\n",
            "Epoch  164  Completed! loss =  0.0\n",
            "Epoch  165  Completed! loss =  0.0\n",
            "Epoch  166  Completed! loss =  0.0\n",
            "Epoch  167  Completed! loss =  0.0\n",
            "Epoch  168  Completed! loss =  0.0\n",
            "Epoch  169  Completed! loss =  0.0\n",
            "Epoch  170  Completed! loss =  0.0\n",
            "Epoch  171  Completed! loss =  0.0\n",
            "Epoch  172  Completed! loss =  0.0\n",
            "Epoch  173  Completed! loss =  0.0\n",
            "Epoch  174  Completed! loss =  0.0\n",
            "Epoch  175  Completed! loss =  0.0\n",
            "Epoch  176  Completed! loss =  0.0\n",
            "Epoch  177  Completed! loss =  0.0\n",
            "Epoch  178  Completed! loss =  0.0\n",
            "Epoch  179  Completed! loss =  0.0\n",
            "Epoch  180  Completed! loss =  0.0\n",
            "Epoch  181  Completed! loss =  0.0\n",
            "Epoch  182  Completed! loss =  0.0\n",
            "Epoch  183  Completed! loss =  0.0\n",
            "Epoch  184  Completed! loss =  0.0\n",
            "Epoch  185  Completed! loss =  0.0\n",
            "Epoch  186  Completed! loss =  0.0\n",
            "Epoch  187  Completed! loss =  0.0\n",
            "Epoch  188  Completed! loss =  0.0\n",
            "Epoch  189  Completed! loss =  0.0\n",
            "Epoch  190  Completed! loss =  0.0\n",
            "Epoch  191  Completed! loss =  0.0\n",
            "Epoch  192  Completed! loss =  0.0\n",
            "Epoch  193  Completed! loss =  0.0\n",
            "Epoch  194  Completed! loss =  0.0\n",
            "Epoch  195  Completed! loss =  0.0\n",
            "Epoch  196  Completed! loss =  0.0\n",
            "Epoch  197  Completed! loss =  0.0\n",
            "Epoch  198  Completed! loss =  0.0\n",
            "Epoch  199  Completed! loss =  0.0\n",
            "Epoch  200  Completed! loss =  0.0\n",
            "Epoch  201  Completed! loss =  0.0\n",
            "Epoch  202  Completed! loss =  0.0\n",
            "Epoch  203  Completed! loss =  0.0\n",
            "Epoch  204  Completed! loss =  0.0\n",
            "Epoch  205  Completed! loss =  0.0\n",
            "Epoch  206  Completed! loss =  0.0\n",
            "Epoch  207  Completed! loss =  0.0\n",
            "Epoch  208  Completed! loss =  0.0\n",
            "Epoch  209  Completed! loss =  0.0\n",
            "Epoch  210  Completed! loss =  0.0\n",
            "Epoch  211  Completed! loss =  0.0\n",
            "Epoch  212  Completed! loss =  0.0\n",
            "Epoch  213  Completed! loss =  0.0\n",
            "Epoch  214  Completed! loss =  0.0\n",
            "Epoch  215  Completed! loss =  0.0\n",
            "Epoch  216  Completed! loss =  0.0\n",
            "Epoch  217  Completed! loss =  0.0\n",
            "Epoch  218  Completed! loss =  0.0\n",
            "Epoch  219  Completed! loss =  0.0\n",
            "Epoch  220  Completed! loss =  0.0\n",
            "Epoch  221  Completed! loss =  0.0\n",
            "Epoch  222  Completed! loss =  0.0\n",
            "Epoch  223  Completed! loss =  0.0\n",
            "Epoch  224  Completed! loss =  0.0\n",
            "Epoch  225  Completed! loss =  0.0\n",
            "Epoch  226  Completed! loss =  0.0\n",
            "Epoch  227  Completed! loss =  0.0\n",
            "Epoch  228  Completed! loss =  0.0\n",
            "Epoch  229  Completed! loss =  0.0\n",
            "Epoch  230  Completed! loss =  0.0\n",
            "Epoch  231  Completed! loss =  0.0\n",
            "Epoch  232  Completed! loss =  0.0\n",
            "Epoch  233  Completed! loss =  0.0\n",
            "Epoch  234  Completed! loss =  0.0\n",
            "Epoch  235  Completed! loss =  0.0\n",
            "Epoch  236  Completed! loss =  0.0\n",
            "Epoch  237  Completed! loss =  0.0\n",
            "Epoch  238  Completed! loss =  0.0\n",
            "Epoch  239  Completed! loss =  0.0\n",
            "Epoch  240  Completed! loss =  0.0\n",
            "Epoch  241  Completed! loss =  0.0\n",
            "Epoch  242  Completed! loss =  0.0\n",
            "Epoch  243  Completed! loss =  0.0\n",
            "Epoch  244  Completed! loss =  0.0\n",
            "Epoch  245  Completed! loss =  0.0\n",
            "Epoch  246  Completed! loss =  0.0\n",
            "Epoch  247  Completed! loss =  0.0\n",
            "Epoch  248  Completed! loss =  0.0\n",
            "Epoch  249  Completed! loss =  0.0\n",
            "Epoch  250  Completed! loss =  0.0\n",
            "Epoch  251  Completed! loss =  0.0\n",
            "Epoch  252  Completed! loss =  0.0\n",
            "Epoch  253  Completed! loss =  0.0\n",
            "Epoch  254  Completed! loss =  0.0\n",
            "Epoch  255  Completed! loss =  0.0\n",
            "Epoch  256  Completed! loss =  0.0\n",
            "Epoch  257  Completed! loss =  0.0\n",
            "Epoch  258  Completed! loss =  0.0\n",
            "Epoch  259  Completed! loss =  0.0\n",
            "Epoch  260  Completed! loss =  0.0\n",
            "Epoch  261  Completed! loss =  0.0\n",
            "Epoch  262  Completed! loss =  0.0\n",
            "Epoch  263  Completed! loss =  0.0\n",
            "Epoch  264  Completed! loss =  0.0\n",
            "Epoch  265  Completed! loss =  0.0\n",
            "Epoch  266  Completed! loss =  0.0\n",
            "Epoch  267  Completed! loss =  0.0\n",
            "Epoch  268  Completed! loss =  0.0\n",
            "Epoch  269  Completed! loss =  0.0\n",
            "Epoch  270  Completed! loss =  0.0\n",
            "Epoch  271  Completed! loss =  0.0\n",
            "Epoch  272  Completed! loss =  0.0\n",
            "Epoch  273  Completed! loss =  0.0\n",
            "Epoch  274  Completed! loss =  0.0\n",
            "Epoch  275  Completed! loss =  0.0\n",
            "Epoch  276  Completed! loss =  0.0\n",
            "Epoch  277  Completed! loss =  0.0\n",
            "Epoch  278  Completed! loss =  0.0\n",
            "Epoch  279  Completed! loss =  0.0\n",
            "Epoch  280  Completed! loss =  0.0\n",
            "Epoch  281  Completed! loss =  0.0\n",
            "Epoch  282  Completed! loss =  0.0\n",
            "Epoch  283  Completed! loss =  0.0\n",
            "Epoch  284  Completed! loss =  0.0\n",
            "Epoch  285  Completed! loss =  0.0\n",
            "Epoch  286  Completed! loss =  0.0\n",
            "Epoch  287  Completed! loss =  0.0\n",
            "Epoch  288  Completed! loss =  0.0\n",
            "Epoch  289  Completed! loss =  0.0\n",
            "Epoch  290  Completed! loss =  0.0\n",
            "Epoch  291  Completed! loss =  0.0\n",
            "Epoch  292  Completed! loss =  0.0\n",
            "Epoch  293  Completed! loss =  0.0\n",
            "Epoch  294  Completed! loss =  0.0\n",
            "Epoch  295  Completed! loss =  0.0\n",
            "Epoch  296  Completed! loss =  0.0\n",
            "Epoch  297  Completed! loss =  0.0\n",
            "Epoch  298  Completed! loss =  0.0\n",
            "Epoch  299  Completed! loss =  0.0\n",
            "Epoch  300  Completed! loss =  0.0\n",
            "Epoch  301  Completed! loss =  0.0\n",
            "Epoch  302  Completed! loss =  0.0\n",
            "Epoch  303  Completed! loss =  0.0\n",
            "Epoch  304  Completed! loss =  0.0\n",
            "Epoch  305  Completed! loss =  0.0\n",
            "Epoch  306  Completed! loss =  0.0\n",
            "Epoch  307  Completed! loss =  0.0\n",
            "Epoch  308  Completed! loss =  0.0\n",
            "Epoch  309  Completed! loss =  0.0\n",
            "Epoch  310  Completed! loss =  0.0\n",
            "Epoch  311  Completed! loss =  0.0\n",
            "Epoch  312  Completed! loss =  0.0\n",
            "Epoch  313  Completed! loss =  0.0\n",
            "Epoch  314  Completed! loss =  0.0\n",
            "Epoch  315  Completed! loss =  0.0\n",
            "Epoch  316  Completed! loss =  0.0\n",
            "Epoch  317  Completed! loss =  0.0\n",
            "Epoch  318  Completed! loss =  0.0\n",
            "Epoch  319  Completed! loss =  0.0\n",
            "Epoch  320  Completed! loss =  0.0\n",
            "Epoch  321  Completed! loss =  0.0\n",
            "Epoch  322  Completed! loss =  0.0\n",
            "Epoch  323  Completed! loss =  0.0\n",
            "Epoch  324  Completed! loss =  0.0\n",
            "Epoch  325  Completed! loss =  0.0\n",
            "Epoch  326  Completed! loss =  0.0\n",
            "Epoch  327  Completed! loss =  0.0\n",
            "Epoch  328  Completed! loss =  0.0\n",
            "Epoch  329  Completed! loss =  0.0\n",
            "Epoch  330  Completed! loss =  0.0\n",
            "Epoch  331  Completed! loss =  0.0\n",
            "Epoch  332  Completed! loss =  0.0\n",
            "Epoch  333  Completed! loss =  0.0\n",
            "Epoch  334  Completed! loss =  0.0\n",
            "Epoch  335  Completed! loss =  0.0\n",
            "Epoch  336  Completed! loss =  0.0\n",
            "Epoch  337  Completed! loss =  0.0\n",
            "Epoch  338  Completed! loss =  0.0\n",
            "Epoch  339  Completed! loss =  0.0\n",
            "Epoch  340  Completed! loss =  0.0\n",
            "Epoch  341  Completed! loss =  0.0\n",
            "Epoch  342  Completed! loss =  0.0\n",
            "Epoch  343  Completed! loss =  0.0\n",
            "Epoch  344  Completed! loss =  0.0\n",
            "Epoch  345  Completed! loss =  0.0\n",
            "Epoch  346  Completed! loss =  0.0\n",
            "Epoch  347  Completed! loss =  0.0\n",
            "Epoch  348  Completed! loss =  0.0\n",
            "Epoch  349  Completed! loss =  0.0\n",
            "Epoch  350  Completed! loss =  0.0\n",
            "Epoch  351  Completed! loss =  0.0\n",
            "Epoch  352  Completed! loss =  0.0\n",
            "Epoch  353  Completed! loss =  0.0\n",
            "Epoch  354  Completed! loss =  0.0\n",
            "Epoch  355  Completed! loss =  0.0\n",
            "Epoch  356  Completed! loss =  0.0\n",
            "Epoch  357  Completed! loss =  0.0\n",
            "Epoch  358  Completed! loss =  0.0\n",
            "Epoch  359  Completed! loss =  0.0\n",
            "Epoch  360  Completed! loss =  0.0\n",
            "Epoch  361  Completed! loss =  0.0\n",
            "Epoch  362  Completed! loss =  0.0\n",
            "Epoch  363  Completed! loss =  0.0\n",
            "Epoch  364  Completed! loss =  0.0\n",
            "Epoch  365  Completed! loss =  0.0\n",
            "Epoch  366  Completed! loss =  0.0\n",
            "Epoch  367  Completed! loss =  0.0\n",
            "Epoch  368  Completed! loss =  0.0\n",
            "Epoch  369  Completed! loss =  0.0\n",
            "Epoch  370  Completed! loss =  0.0\n",
            "Epoch  371  Completed! loss =  0.0\n",
            "Epoch  372  Completed! loss =  0.0\n",
            "Epoch  373  Completed! loss =  0.0\n",
            "Epoch  374  Completed! loss =  0.0\n",
            "Epoch  375  Completed! loss =  0.0\n",
            "Epoch  376  Completed! loss =  0.0\n",
            "Epoch  377  Completed! loss =  0.0\n",
            "Epoch  378  Completed! loss =  0.0\n",
            "Epoch  379  Completed! loss =  0.0\n",
            "Epoch  380  Completed! loss =  0.0\n",
            "Epoch  381  Completed! loss =  0.0\n",
            "Epoch  382  Completed! loss =  0.0\n",
            "Epoch  383  Completed! loss =  0.0\n",
            "Epoch  384  Completed! loss =  0.0\n",
            "Epoch  385  Completed! loss =  0.0\n",
            "Epoch  386  Completed! loss =  0.0\n",
            "Epoch  387  Completed! loss =  0.0\n",
            "Epoch  388  Completed! loss =  0.0\n",
            "Epoch  389  Completed! loss =  0.0\n",
            "Epoch  390  Completed! loss =  0.0\n",
            "Epoch  391  Completed! loss =  0.0\n",
            "Epoch  392  Completed! loss =  0.0\n",
            "Epoch  393  Completed! loss =  0.0\n",
            "Epoch  394  Completed! loss =  0.0\n",
            "Epoch  395  Completed! loss =  0.0\n",
            "Epoch  396  Completed! loss =  0.0\n",
            "Epoch  397  Completed! loss =  0.0\n",
            "Epoch  398  Completed! loss =  0.0\n",
            "Epoch  399  Completed! loss =  0.0\n",
            "Epoch  400  Completed! loss =  0.0\n",
            "Epoch  401  Completed! loss =  0.0\n",
            "Epoch  402  Completed! loss =  0.0\n",
            "Epoch  403  Completed! loss =  0.0\n",
            "Epoch  404  Completed! loss =  0.0\n",
            "Epoch  405  Completed! loss =  0.0\n",
            "Epoch  406  Completed! loss =  0.0\n",
            "Epoch  407  Completed! loss =  0.0\n",
            "Epoch  408  Completed! loss =  0.0\n",
            "Epoch  409  Completed! loss =  0.0\n",
            "Epoch  410  Completed! loss =  0.0\n",
            "Epoch  411  Completed! loss =  0.0\n",
            "Epoch  412  Completed! loss =  0.0\n",
            "Epoch  413  Completed! loss =  0.0\n",
            "Epoch  414  Completed! loss =  0.0\n",
            "Epoch  415  Completed! loss =  0.0\n",
            "Epoch  416  Completed! loss =  0.0\n",
            "Epoch  417  Completed! loss =  0.0\n",
            "Epoch  418  Completed! loss =  0.0\n",
            "Epoch  419  Completed! loss =  0.0\n",
            "Epoch  420  Completed! loss =  0.0\n",
            "Epoch  421  Completed! loss =  0.0\n",
            "Epoch  422  Completed! loss =  0.0\n",
            "Epoch  423  Completed! loss =  0.0\n",
            "Epoch  424  Completed! loss =  0.0\n",
            "Epoch  425  Completed! loss =  0.0\n",
            "Epoch  426  Completed! loss =  0.0\n",
            "Epoch  427  Completed! loss =  0.0\n",
            "Epoch  428  Completed! loss =  0.0\n",
            "Epoch  429  Completed! loss =  0.0\n",
            "Epoch  430  Completed! loss =  0.0\n",
            "Epoch  431  Completed! loss =  0.0\n",
            "Epoch  432  Completed! loss =  0.0\n",
            "Epoch  433  Completed! loss =  0.0\n",
            "Epoch  434  Completed! loss =  0.0\n",
            "Epoch  435  Completed! loss =  0.0\n",
            "Epoch  436  Completed! loss =  0.0\n",
            "Epoch  437  Completed! loss =  0.0\n",
            "Epoch  438  Completed! loss =  0.0\n",
            "Epoch  439  Completed! loss =  0.0\n",
            "Epoch  440  Completed! loss =  0.0\n",
            "Epoch  441  Completed! loss =  0.0\n",
            "Epoch  442  Completed! loss =  0.0\n",
            "Epoch  443  Completed! loss =  0.0\n",
            "Epoch  444  Completed! loss =  0.0\n",
            "Epoch  445  Completed! loss =  0.0\n",
            "Epoch  446  Completed! loss =  0.0\n",
            "Epoch  447  Completed! loss =  0.0\n",
            "Epoch  448  Completed! loss =  0.0\n",
            "Epoch  449  Completed! loss =  0.0\n",
            "Epoch  450  Completed! loss =  0.0\n",
            "Epoch  451  Completed! loss =  0.0\n",
            "Epoch  452  Completed! loss =  0.0\n",
            "Epoch  453  Completed! loss =  0.0\n",
            "Epoch  454  Completed! loss =  0.0\n",
            "Epoch  455  Completed! loss =  0.0\n",
            "Epoch  456  Completed! loss =  0.0\n",
            "Epoch  457  Completed! loss =  0.0\n",
            "Epoch  458  Completed! loss =  0.0\n",
            "Epoch  459  Completed! loss =  0.0\n",
            "Epoch  460  Completed! loss =  0.0\n",
            "Epoch  461  Completed! loss =  0.0\n",
            "Epoch  462  Completed! loss =  0.0\n",
            "Epoch  463  Completed! loss =  0.0\n",
            "Epoch  464  Completed! loss =  0.0\n",
            "Epoch  465  Completed! loss =  0.0\n",
            "Epoch  466  Completed! loss =  0.0\n",
            "Epoch  467  Completed! loss =  0.0\n",
            "Epoch  468  Completed! loss =  0.0\n",
            "Epoch  469  Completed! loss =  0.0\n",
            "Epoch  470  Completed! loss =  0.0\n",
            "Epoch  471  Completed! loss =  0.0\n",
            "Epoch  472  Completed! loss =  0.0\n",
            "Epoch  473  Completed! loss =  0.0\n",
            "Epoch  474  Completed! loss =  0.0\n",
            "Epoch  475  Completed! loss =  0.0\n",
            "Epoch  476  Completed! loss =  0.0\n",
            "Epoch  477  Completed! loss =  0.0\n",
            "Epoch  478  Completed! loss =  0.0\n",
            "Epoch  479  Completed! loss =  0.0\n",
            "Epoch  480  Completed! loss =  0.0\n",
            "Epoch  481  Completed! loss =  0.0\n",
            "Epoch  482  Completed! loss =  0.0\n",
            "Epoch  483  Completed! loss =  0.0\n",
            "Epoch  484  Completed! loss =  0.0\n",
            "Epoch  485  Completed! loss =  0.0\n",
            "Epoch  486  Completed! loss =  0.0\n",
            "Epoch  487  Completed! loss =  0.0\n",
            "Epoch  488  Completed! loss =  0.0\n",
            "Epoch  489  Completed! loss =  0.0\n",
            "Epoch  490  Completed! loss =  0.0\n",
            "Epoch  491  Completed! loss =  0.0\n",
            "Epoch  492  Completed! loss =  0.0\n",
            "Epoch  493  Completed! loss =  0.0\n",
            "Epoch  494  Completed! loss =  0.0\n",
            "Epoch  495  Completed! loss =  0.0\n",
            "Epoch  496  Completed! loss =  0.0\n",
            "Epoch  497  Completed! loss =  0.0\n",
            "Epoch  498  Completed! loss =  0.0\n",
            "Epoch  499  Completed! loss =  0.0\n",
            "Epoch  500  Completed! loss =  0.0\n",
            "Epoch  501  Completed! loss =  0.0\n",
            "Epoch  502  Completed! loss =  0.0\n",
            "Epoch  503  Completed! loss =  0.0\n",
            "Epoch  504  Completed! loss =  0.0\n",
            "Epoch  505  Completed! loss =  0.0\n",
            "Epoch  506  Completed! loss =  0.0\n",
            "Epoch  507  Completed! loss =  0.0\n",
            "Epoch  508  Completed! loss =  0.0\n",
            "Epoch  509  Completed! loss =  0.0\n",
            "Epoch  510  Completed! loss =  0.0\n",
            "Epoch  511  Completed! loss =  0.0\n",
            "Epoch  512  Completed! loss =  0.0\n",
            "Epoch  513  Completed! loss =  0.0\n",
            "Epoch  514  Completed! loss =  0.0\n",
            "Epoch  515  Completed! loss =  0.0\n",
            "Epoch  516  Completed! loss =  0.0\n",
            "Epoch  517  Completed! loss =  0.0\n",
            "Epoch  518  Completed! loss =  0.0\n",
            "Epoch  519  Completed! loss =  0.0\n",
            "Epoch  520  Completed! loss =  0.0\n",
            "Epoch  521  Completed! loss =  0.0\n",
            "Epoch  522  Completed! loss =  0.0\n",
            "Epoch  523  Completed! loss =  0.0\n",
            "Epoch  524  Completed! loss =  0.0\n",
            "Epoch  525  Completed! loss =  0.0\n",
            "Epoch  526  Completed! loss =  0.0\n",
            "Epoch  527  Completed! loss =  0.0\n",
            "Epoch  528  Completed! loss =  0.0\n",
            "Epoch  529  Completed! loss =  0.0\n",
            "Epoch  530  Completed! loss =  0.0\n",
            "Epoch  531  Completed! loss =  0.0\n",
            "Epoch  532  Completed! loss =  0.0\n",
            "Epoch  533  Completed! loss =  0.0\n",
            "Epoch  534  Completed! loss =  0.0\n",
            "Epoch  535  Completed! loss =  0.0\n",
            "Epoch  536  Completed! loss =  0.0\n",
            "Epoch  537  Completed! loss =  0.0\n",
            "Epoch  538  Completed! loss =  0.0\n",
            "Epoch  539  Completed! loss =  0.0\n",
            "Epoch  540  Completed! loss =  0.0\n",
            "Epoch  541  Completed! loss =  0.0\n",
            "Epoch  542  Completed! loss =  0.0\n",
            "Epoch  543  Completed! loss =  0.0\n",
            "Epoch  544  Completed! loss =  0.0\n",
            "Epoch  545  Completed! loss =  0.0\n",
            "Epoch  546  Completed! loss =  0.0\n",
            "Epoch  547  Completed! loss =  0.0\n",
            "Epoch  548  Completed! loss =  0.0\n",
            "Epoch  549  Completed! loss =  0.0\n",
            "Epoch  550  Completed! loss =  0.0\n",
            "Epoch  551  Completed! loss =  0.0\n",
            "Epoch  552  Completed! loss =  0.0\n",
            "Epoch  553  Completed! loss =  0.0\n",
            "Epoch  554  Completed! loss =  0.0\n",
            "Epoch  555  Completed! loss =  0.0\n",
            "Epoch  556  Completed! loss =  0.0\n",
            "Epoch  557  Completed! loss =  0.0\n",
            "Epoch  558  Completed! loss =  0.0\n",
            "Epoch  559  Completed! loss =  0.0\n",
            "Epoch  560  Completed! loss =  0.0\n",
            "Epoch  561  Completed! loss =  0.0\n",
            "Epoch  562  Completed! loss =  0.0\n",
            "Epoch  563  Completed! loss =  0.0\n",
            "Epoch  564  Completed! loss =  0.0\n",
            "Epoch  565  Completed! loss =  0.0\n",
            "Epoch  566  Completed! loss =  0.0\n",
            "Epoch  567  Completed! loss =  0.0\n",
            "Epoch  568  Completed! loss =  0.0\n",
            "Epoch  569  Completed! loss =  0.0\n",
            "Epoch  570  Completed! loss =  0.0\n",
            "Epoch  571  Completed! loss =  0.0\n",
            "Epoch  572  Completed! loss =  0.0\n",
            "Epoch  573  Completed! loss =  0.0\n",
            "Epoch  574  Completed! loss =  0.0\n",
            "Epoch  575  Completed! loss =  0.0\n",
            "Epoch  576  Completed! loss =  0.0\n",
            "Epoch  577  Completed! loss =  0.0\n",
            "Epoch  578  Completed! loss =  0.0\n",
            "Epoch  579  Completed! loss =  0.0\n",
            "Epoch  580  Completed! loss =  0.0\n",
            "Epoch  581  Completed! loss =  0.0\n",
            "Epoch  582  Completed! loss =  0.0\n",
            "Epoch  583  Completed! loss =  0.0\n",
            "Epoch  584  Completed! loss =  0.0\n",
            "Epoch  585  Completed! loss =  0.0\n",
            "Epoch  586  Completed! loss =  0.0\n",
            "Epoch  587  Completed! loss =  0.0\n",
            "Epoch  588  Completed! loss =  0.0\n",
            "Epoch  589  Completed! loss =  0.0\n",
            "Epoch  590  Completed! loss =  0.0\n",
            "Epoch  591  Completed! loss =  0.0\n",
            "Epoch  592  Completed! loss =  0.0\n",
            "Epoch  593  Completed! loss =  0.0\n",
            "Epoch  594  Completed! loss =  0.0\n",
            "Epoch  595  Completed! loss =  0.0\n",
            "Epoch  596  Completed! loss =  0.0\n",
            "Epoch  597  Completed! loss =  0.0\n",
            "Epoch  598  Completed! loss =  0.0\n",
            "Epoch  599  Completed! loss =  0.0\n",
            "Epoch  600  Completed! loss =  0.0\n",
            "Epoch  601  Completed! loss =  0.0\n",
            "Epoch  602  Completed! loss =  0.0\n",
            "Epoch  603  Completed! loss =  0.0\n",
            "Epoch  604  Completed! loss =  0.0\n",
            "Epoch  605  Completed! loss =  0.0\n",
            "Epoch  606  Completed! loss =  0.0\n",
            "Epoch  607  Completed! loss =  0.0\n",
            "Epoch  608  Completed! loss =  0.0\n",
            "Epoch  609  Completed! loss =  0.0\n",
            "Epoch  610  Completed! loss =  0.0\n",
            "Epoch  611  Completed! loss =  0.0\n",
            "Epoch  612  Completed! loss =  0.0\n",
            "Epoch  613  Completed! loss =  0.0\n",
            "Epoch  614  Completed! loss =  0.0\n",
            "Epoch  615  Completed! loss =  0.0\n",
            "Epoch  616  Completed! loss =  0.0\n",
            "Epoch  617  Completed! loss =  0.0\n",
            "Epoch  618  Completed! loss =  0.0\n",
            "Epoch  619  Completed! loss =  0.0\n",
            "Epoch  620  Completed! loss =  0.0\n",
            "Epoch  621  Completed! loss =  0.0\n",
            "Epoch  622  Completed! loss =  0.0\n",
            "Epoch  623  Completed! loss =  0.0\n",
            "Epoch  624  Completed! loss =  0.0\n",
            "Epoch  625  Completed! loss =  0.0\n",
            "Epoch  626  Completed! loss =  0.0\n",
            "Epoch  627  Completed! loss =  0.0\n",
            "Epoch  628  Completed! loss =  0.0\n",
            "Epoch  629  Completed! loss =  0.0\n",
            "Epoch  630  Completed! loss =  0.0\n",
            "Epoch  631  Completed! loss =  0.0\n",
            "Epoch  632  Completed! loss =  0.0\n",
            "Epoch  633  Completed! loss =  0.0\n",
            "Epoch  634  Completed! loss =  0.0\n",
            "Epoch  635  Completed! loss =  0.0\n",
            "Epoch  636  Completed! loss =  0.0\n",
            "Epoch  637  Completed! loss =  0.0\n",
            "Epoch  638  Completed! loss =  0.0\n",
            "Epoch  639  Completed! loss =  0.0\n",
            "Epoch  640  Completed! loss =  0.0\n",
            "Epoch  641  Completed! loss =  0.0\n",
            "Epoch  642  Completed! loss =  0.0\n",
            "Epoch  643  Completed! loss =  0.0\n",
            "Epoch  644  Completed! loss =  0.0\n",
            "Epoch  645  Completed! loss =  0.0\n",
            "Epoch  646  Completed! loss =  0.0\n",
            "Epoch  647  Completed! loss =  0.0\n",
            "Epoch  648  Completed! loss =  0.0\n",
            "Epoch  649  Completed! loss =  0.0\n",
            "Epoch  650  Completed! loss =  0.0\n",
            "Epoch  651  Completed! loss =  0.0\n",
            "Epoch  652  Completed! loss =  0.0\n",
            "Epoch  653  Completed! loss =  0.0\n",
            "Epoch  654  Completed! loss =  0.0\n",
            "Epoch  655  Completed! loss =  0.0\n",
            "Epoch  656  Completed! loss =  0.0\n",
            "Epoch  657  Completed! loss =  0.0\n",
            "Epoch  658  Completed! loss =  0.0\n",
            "Epoch  659  Completed! loss =  0.0\n",
            "Epoch  660  Completed! loss =  0.0\n",
            "Epoch  661  Completed! loss =  0.0\n",
            "Epoch  662  Completed! loss =  0.0\n",
            "Epoch  663  Completed! loss =  0.0\n",
            "Epoch  664  Completed! loss =  0.0\n",
            "Epoch  665  Completed! loss =  0.0\n",
            "Epoch  666  Completed! loss =  0.0\n",
            "Epoch  667  Completed! loss =  0.0\n",
            "Epoch  668  Completed! loss =  0.0\n",
            "Epoch  669  Completed! loss =  0.0\n",
            "Epoch  670  Completed! loss =  0.0\n",
            "Epoch  671  Completed! loss =  0.0\n",
            "Epoch  672  Completed! loss =  0.0\n",
            "Epoch  673  Completed! loss =  0.0\n",
            "Epoch  674  Completed! loss =  0.0\n",
            "Epoch  675  Completed! loss =  0.0\n",
            "Epoch  676  Completed! loss =  0.0\n",
            "Epoch  677  Completed! loss =  0.0\n",
            "Epoch  678  Completed! loss =  0.0\n",
            "Epoch  679  Completed! loss =  0.0\n",
            "Epoch  680  Completed! loss =  0.0\n",
            "Epoch  681  Completed! loss =  0.0\n",
            "Epoch  682  Completed! loss =  0.0\n",
            "Epoch  683  Completed! loss =  0.0\n",
            "Epoch  684  Completed! loss =  0.0\n",
            "Epoch  685  Completed! loss =  0.0\n",
            "Epoch  686  Completed! loss =  0.0\n",
            "Epoch  687  Completed! loss =  0.0\n",
            "Epoch  688  Completed! loss =  0.0\n",
            "Epoch  689  Completed! loss =  0.0\n",
            "Epoch  690  Completed! loss =  0.0\n",
            "Epoch  691  Completed! loss =  0.0\n",
            "Epoch  692  Completed! loss =  0.0\n",
            "Epoch  693  Completed! loss =  0.0\n",
            "Epoch  694  Completed! loss =  0.0\n",
            "Epoch  695  Completed! loss =  0.0\n",
            "Epoch  696  Completed! loss =  0.0\n",
            "Epoch  697  Completed! loss =  0.0\n",
            "Epoch  698  Completed! loss =  0.0\n",
            "Epoch  699  Completed! loss =  0.0\n",
            "Epoch  700  Completed! loss =  0.0\n",
            "Epoch  701  Completed! loss =  0.0\n",
            "Epoch  702  Completed! loss =  0.0\n",
            "Epoch  703  Completed! loss =  0.0\n",
            "Epoch  704  Completed! loss =  0.0\n",
            "Epoch  705  Completed! loss =  0.0\n",
            "Epoch  706  Completed! loss =  0.0\n",
            "Epoch  707  Completed! loss =  0.0\n",
            "Epoch  708  Completed! loss =  0.0\n",
            "Epoch  709  Completed! loss =  0.0\n",
            "Epoch  710  Completed! loss =  0.0\n",
            "Epoch  711  Completed! loss =  0.0\n",
            "Epoch  712  Completed! loss =  0.0\n",
            "Epoch  713  Completed! loss =  0.0\n",
            "Epoch  714  Completed! loss =  0.0\n",
            "Epoch  715  Completed! loss =  0.0\n",
            "Epoch  716  Completed! loss =  0.0\n",
            "Epoch  717  Completed! loss =  0.0\n",
            "Epoch  718  Completed! loss =  0.0\n",
            "Epoch  719  Completed! loss =  0.0\n",
            "Epoch  720  Completed! loss =  0.0\n",
            "Epoch  721  Completed! loss =  0.0\n",
            "Epoch  722  Completed! loss =  0.0\n",
            "Epoch  723  Completed! loss =  0.0\n",
            "Epoch  724  Completed! loss =  0.0\n",
            "Epoch  725  Completed! loss =  0.0\n",
            "Epoch  726  Completed! loss =  0.0\n",
            "Epoch  727  Completed! loss =  0.0\n",
            "Epoch  728  Completed! loss =  0.0\n",
            "Epoch  729  Completed! loss =  0.0\n",
            "Epoch  730  Completed! loss =  0.0\n",
            "Epoch  731  Completed! loss =  0.0\n",
            "Epoch  732  Completed! loss =  0.0\n",
            "Epoch  733  Completed! loss =  0.0\n",
            "Epoch  734  Completed! loss =  0.0\n",
            "Epoch  735  Completed! loss =  0.0\n",
            "Epoch  736  Completed! loss =  0.0\n",
            "Epoch  737  Completed! loss =  0.0\n",
            "Epoch  738  Completed! loss =  0.0\n",
            "Epoch  739  Completed! loss =  0.0\n",
            "Epoch  740  Completed! loss =  0.0\n",
            "Epoch  741  Completed! loss =  0.0\n",
            "Epoch  742  Completed! loss =  0.0\n",
            "Epoch  743  Completed! loss =  0.0\n",
            "Epoch  744  Completed! loss =  0.0\n",
            "Epoch  745  Completed! loss =  0.0\n",
            "Epoch  746  Completed! loss =  0.0\n",
            "Epoch  747  Completed! loss =  0.0\n",
            "Epoch  748  Completed! loss =  0.0\n",
            "Epoch  749  Completed! loss =  0.0\n",
            "Epoch  750  Completed! loss =  0.0\n",
            "Epoch  751  Completed! loss =  0.0\n",
            "Epoch  752  Completed! loss =  0.0\n",
            "Epoch  753  Completed! loss =  0.0\n",
            "Epoch  754  Completed! loss =  0.0\n",
            "Epoch  755  Completed! loss =  0.0\n",
            "Epoch  756  Completed! loss =  0.0\n",
            "Epoch  757  Completed! loss =  0.0\n",
            "Epoch  758  Completed! loss =  0.0\n",
            "Epoch  759  Completed! loss =  0.0\n",
            "Epoch  760  Completed! loss =  0.0\n",
            "Epoch  761  Completed! loss =  0.0\n",
            "Epoch  762  Completed! loss =  0.0\n",
            "Epoch  763  Completed! loss =  0.0\n",
            "Epoch  764  Completed! loss =  0.0\n",
            "Epoch  765  Completed! loss =  0.0\n",
            "Epoch  766  Completed! loss =  0.0\n",
            "Epoch  767  Completed! loss =  0.0\n",
            "Epoch  768  Completed! loss =  0.0\n",
            "Epoch  769  Completed! loss =  0.0\n",
            "Epoch  770  Completed! loss =  0.0\n",
            "Epoch  771  Completed! loss =  0.0\n",
            "Epoch  772  Completed! loss =  0.0\n",
            "Epoch  773  Completed! loss =  0.0\n",
            "Epoch  774  Completed! loss =  0.0\n",
            "Epoch  775  Completed! loss =  0.0\n",
            "Epoch  776  Completed! loss =  0.0\n",
            "Epoch  777  Completed! loss =  0.0\n",
            "Epoch  778  Completed! loss =  0.0\n",
            "Epoch  779  Completed! loss =  0.0\n",
            "Epoch  780  Completed! loss =  0.0\n",
            "Epoch  781  Completed! loss =  0.0\n",
            "Epoch  782  Completed! loss =  0.0\n",
            "Epoch  783  Completed! loss =  0.0\n",
            "Epoch  784  Completed! loss =  0.0\n",
            "Epoch  785  Completed! loss =  0.0\n",
            "Epoch  786  Completed! loss =  0.0\n",
            "Epoch  787  Completed! loss =  0.0\n",
            "Epoch  788  Completed! loss =  0.0\n",
            "Epoch  789  Completed! loss =  0.0\n",
            "Epoch  790  Completed! loss =  0.0\n",
            "Epoch  791  Completed! loss =  0.0\n",
            "Epoch  792  Completed! loss =  0.0\n",
            "Epoch  793  Completed! loss =  0.0\n",
            "Epoch  794  Completed! loss =  0.0\n",
            "Epoch  795  Completed! loss =  0.0\n",
            "Epoch  796  Completed! loss =  0.0\n",
            "Epoch  797  Completed! loss =  0.0\n",
            "Epoch  798  Completed! loss =  0.0\n",
            "Epoch  799  Completed! loss =  0.0\n",
            "Epoch  800  Completed! loss =  0.0\n",
            "Epoch  801  Completed! loss =  0.0\n",
            "Epoch  802  Completed! loss =  0.0\n",
            "Epoch  803  Completed! loss =  0.0\n",
            "Epoch  804  Completed! loss =  0.0\n",
            "Epoch  805  Completed! loss =  0.0\n",
            "Epoch  806  Completed! loss =  0.0\n",
            "Epoch  807  Completed! loss =  0.0\n",
            "Epoch  808  Completed! loss =  0.0\n",
            "Epoch  809  Completed! loss =  0.0\n",
            "Epoch  810  Completed! loss =  0.0\n",
            "Epoch  811  Completed! loss =  0.0\n",
            "Epoch  812  Completed! loss =  0.0\n",
            "Epoch  813  Completed! loss =  0.0\n",
            "Epoch  814  Completed! loss =  0.0\n",
            "Epoch  815  Completed! loss =  0.0\n",
            "Epoch  816  Completed! loss =  0.0\n",
            "Epoch  817  Completed! loss =  0.0\n",
            "Epoch  818  Completed! loss =  0.0\n",
            "Epoch  819  Completed! loss =  0.0\n",
            "Epoch  820  Completed! loss =  0.0\n",
            "Epoch  821  Completed! loss =  0.0\n",
            "Epoch  822  Completed! loss =  0.0\n",
            "Epoch  823  Completed! loss =  0.0\n",
            "Epoch  824  Completed! loss =  0.0\n",
            "Epoch  825  Completed! loss =  0.0\n",
            "Epoch  826  Completed! loss =  0.0\n",
            "Epoch  827  Completed! loss =  0.0\n",
            "Epoch  828  Completed! loss =  0.0\n",
            "Epoch  829  Completed! loss =  0.0\n",
            "Epoch  830  Completed! loss =  0.0\n",
            "Epoch  831  Completed! loss =  0.0\n",
            "Epoch  832  Completed! loss =  0.0\n",
            "Epoch  833  Completed! loss =  0.0\n",
            "Epoch  834  Completed! loss =  0.0\n",
            "Epoch  835  Completed! loss =  0.0\n",
            "Epoch  836  Completed! loss =  0.0\n",
            "Epoch  837  Completed! loss =  0.0\n",
            "Epoch  838  Completed! loss =  0.0\n",
            "Epoch  839  Completed! loss =  0.0\n",
            "Epoch  840  Completed! loss =  0.0\n",
            "Epoch  841  Completed! loss =  0.0\n",
            "Epoch  842  Completed! loss =  0.0\n",
            "Epoch  843  Completed! loss =  0.0\n",
            "Epoch  844  Completed! loss =  0.0\n",
            "Epoch  845  Completed! loss =  0.0\n",
            "Epoch  846  Completed! loss =  0.0\n",
            "Epoch  847  Completed! loss =  0.0\n",
            "Epoch  848  Completed! loss =  0.0\n",
            "Epoch  849  Completed! loss =  0.0\n",
            "Epoch  850  Completed! loss =  0.0\n",
            "Epoch  851  Completed! loss =  0.0\n",
            "Epoch  852  Completed! loss =  0.0\n",
            "Epoch  853  Completed! loss =  0.0\n",
            "Epoch  854  Completed! loss =  0.0\n",
            "Epoch  855  Completed! loss =  0.0\n",
            "Epoch  856  Completed! loss =  0.0\n",
            "Epoch  857  Completed! loss =  0.0\n",
            "Epoch  858  Completed! loss =  0.0\n",
            "Epoch  859  Completed! loss =  0.0\n",
            "Epoch  860  Completed! loss =  0.0\n",
            "Epoch  861  Completed! loss =  0.0\n",
            "Epoch  862  Completed! loss =  0.0\n",
            "Epoch  863  Completed! loss =  0.0\n",
            "Epoch  864  Completed! loss =  0.0\n",
            "Epoch  865  Completed! loss =  0.0\n",
            "Epoch  866  Completed! loss =  0.0\n",
            "Epoch  867  Completed! loss =  0.0\n",
            "Epoch  868  Completed! loss =  0.0\n",
            "Epoch  869  Completed! loss =  0.0\n",
            "Epoch  870  Completed! loss =  0.0\n",
            "Epoch  871  Completed! loss =  0.0\n",
            "Epoch  872  Completed! loss =  0.0\n",
            "Epoch  873  Completed! loss =  0.0\n",
            "Epoch  874  Completed! loss =  0.0\n",
            "Epoch  875  Completed! loss =  0.0\n",
            "Epoch  876  Completed! loss =  0.0\n",
            "Epoch  877  Completed! loss =  0.0\n",
            "Epoch  878  Completed! loss =  0.0\n",
            "Epoch  879  Completed! loss =  0.0\n",
            "Epoch  880  Completed! loss =  0.0\n",
            "Epoch  881  Completed! loss =  0.0\n",
            "Epoch  882  Completed! loss =  0.0\n",
            "Epoch  883  Completed! loss =  0.0\n",
            "Epoch  884  Completed! loss =  0.0\n",
            "Epoch  885  Completed! loss =  0.0\n",
            "Epoch  886  Completed! loss =  0.0\n",
            "Epoch  887  Completed! loss =  0.0\n",
            "Epoch  888  Completed! loss =  0.0\n",
            "Epoch  889  Completed! loss =  0.0\n",
            "Epoch  890  Completed! loss =  0.0\n",
            "Epoch  891  Completed! loss =  0.0\n",
            "Epoch  892  Completed! loss =  0.0\n",
            "Epoch  893  Completed! loss =  0.0\n",
            "Epoch  894  Completed! loss =  0.0\n",
            "Epoch  895  Completed! loss =  0.0\n",
            "Epoch  896  Completed! loss =  0.0\n",
            "Epoch  897  Completed! loss =  0.0\n",
            "Epoch  898  Completed! loss =  0.0\n",
            "Epoch  899  Completed! loss =  0.0\n",
            "Epoch  900  Completed! loss =  0.0\n",
            "Epoch  901  Completed! loss =  0.0\n",
            "Epoch  902  Completed! loss =  0.0\n",
            "Epoch  903  Completed! loss =  0.0\n",
            "Epoch  904  Completed! loss =  0.0\n",
            "Epoch  905  Completed! loss =  0.0\n",
            "Epoch  906  Completed! loss =  0.0\n",
            "Epoch  907  Completed! loss =  0.0\n",
            "Epoch  908  Completed! loss =  0.0\n",
            "Epoch  909  Completed! loss =  0.0\n",
            "Epoch  910  Completed! loss =  0.0\n",
            "Epoch  911  Completed! loss =  0.0\n",
            "Epoch  912  Completed! loss =  0.0\n",
            "Epoch  913  Completed! loss =  0.0\n",
            "Epoch  914  Completed! loss =  0.0\n",
            "Epoch  915  Completed! loss =  0.0\n",
            "Epoch  916  Completed! loss =  0.0\n",
            "Epoch  917  Completed! loss =  0.0\n",
            "Epoch  918  Completed! loss =  0.0\n",
            "Epoch  919  Completed! loss =  0.0\n",
            "Epoch  920  Completed! loss =  0.0\n",
            "Epoch  921  Completed! loss =  0.0\n",
            "Epoch  922  Completed! loss =  0.0\n",
            "Epoch  923  Completed! loss =  0.0\n",
            "Epoch  924  Completed! loss =  0.0\n",
            "Epoch  925  Completed! loss =  0.0\n",
            "Epoch  926  Completed! loss =  0.0\n",
            "Epoch  927  Completed! loss =  0.0\n",
            "Epoch  928  Completed! loss =  0.0\n",
            "Epoch  929  Completed! loss =  0.0\n",
            "Epoch  930  Completed! loss =  0.0\n",
            "Epoch  931  Completed! loss =  0.0\n",
            "Epoch  932  Completed! loss =  0.0\n",
            "Epoch  933  Completed! loss =  0.0\n",
            "Epoch  934  Completed! loss =  0.0\n",
            "Epoch  935  Completed! loss =  0.0\n",
            "Epoch  936  Completed! loss =  0.0\n",
            "Epoch  937  Completed! loss =  0.0\n",
            "Epoch  938  Completed! loss =  0.0\n",
            "Epoch  939  Completed! loss =  0.0\n",
            "Epoch  940  Completed! loss =  0.0\n",
            "Epoch  941  Completed! loss =  0.0\n",
            "Epoch  942  Completed! loss =  0.0\n",
            "Epoch  943  Completed! loss =  0.0\n",
            "Epoch  944  Completed! loss =  0.0\n",
            "Epoch  945  Completed! loss =  0.0\n",
            "Epoch  946  Completed! loss =  0.0\n",
            "Epoch  947  Completed! loss =  0.0\n",
            "Epoch  948  Completed! loss =  0.0\n",
            "Epoch  949  Completed! loss =  0.0\n",
            "Epoch  950  Completed! loss =  0.0\n",
            "Epoch  951  Completed! loss =  0.0\n",
            "Epoch  952  Completed! loss =  0.0\n",
            "Epoch  953  Completed! loss =  0.0\n",
            "Epoch  954  Completed! loss =  0.0\n",
            "Epoch  955  Completed! loss =  0.0\n",
            "Epoch  956  Completed! loss =  0.0\n",
            "Epoch  957  Completed! loss =  0.0\n",
            "Epoch  958  Completed! loss =  0.0\n",
            "Epoch  959  Completed! loss =  0.0\n",
            "Epoch  960  Completed! loss =  0.0\n",
            "Epoch  961  Completed! loss =  0.0\n",
            "Epoch  962  Completed! loss =  0.0\n",
            "Epoch  963  Completed! loss =  0.0\n",
            "Epoch  964  Completed! loss =  0.0\n",
            "Epoch  965  Completed! loss =  0.0\n",
            "Epoch  966  Completed! loss =  0.0\n",
            "Epoch  967  Completed! loss =  0.0\n",
            "Epoch  968  Completed! loss =  0.0\n",
            "Epoch  969  Completed! loss =  0.0\n",
            "Epoch  970  Completed! loss =  0.0\n",
            "Epoch  971  Completed! loss =  0.0\n",
            "Epoch  972  Completed! loss =  0.0\n",
            "Epoch  973  Completed! loss =  0.0\n",
            "Epoch  974  Completed! loss =  0.0\n",
            "Epoch  975  Completed! loss =  0.0\n",
            "Epoch  976  Completed! loss =  0.0\n",
            "Epoch  977  Completed! loss =  0.0\n",
            "Epoch  978  Completed! loss =  0.0\n",
            "Epoch  979  Completed! loss =  0.0\n",
            "Epoch  980  Completed! loss =  0.0\n",
            "Epoch  981  Completed! loss =  0.0\n",
            "Epoch  982  Completed! loss =  0.0\n",
            "Epoch  983  Completed! loss =  0.0\n",
            "Epoch  984  Completed! loss =  0.0\n",
            "Epoch  985  Completed! loss =  0.0\n",
            "Epoch  986  Completed! loss =  0.0\n",
            "Epoch  987  Completed! loss =  0.0\n",
            "Epoch  988  Completed! loss =  0.0\n",
            "Epoch  989  Completed! loss =  0.0\n",
            "Epoch  990  Completed! loss =  0.0\n",
            "Epoch  991  Completed! loss =  0.0\n",
            "Epoch  992  Completed! loss =  0.0\n",
            "Epoch  993  Completed! loss =  0.0\n",
            "Epoch  994  Completed! loss =  0.0\n",
            "Epoch  995  Completed! loss =  0.0\n",
            "Epoch  996  Completed! loss =  0.0\n",
            "Epoch  997  Completed! loss =  0.0\n",
            "Epoch  998  Completed! loss =  0.0\n",
            "Epoch  999  Completed! loss =  0.0\n",
            "Epoch  1000  Completed! loss =  0.0\n",
            "Training completed!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation and Visualization**\n",
        "Lets plot how loss varies with epochs\n"
      ],
      "metadata": {
        "id": "TDH-7NHQT50f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_loss = loss()\n",
        "\n",
        "#print(\"Loss on test data = \",test_loss)\n",
        "\n",
        "# Visualization of loss\n",
        "\n",
        "plt.plot(range(epochs), train_loss)                   # plot loss versus epochs\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d7JRB_nJUEkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b7940488-673b-42fa-a9a4-a4604aa04aee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep Learning**\n",
        "In this section We will build a simple multilayer perceptron network(**MLP**) in TensorFlow"
      ],
      "metadata": {
        "id": "iQ5wPjPb57pb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGoZEKIbdXZD"
      },
      "outputs": [],
      "source": [
        "# Lets import the required libraries\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThuZ51gEdXZF"
      },
      "source": [
        "### **Load Dataset**\n",
        "We will be using MNIST dataset of handwritten digits\n",
        "\n",
        "Just run the cell below to load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj3J8Dp-dXZG"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"No. of training examples = \",x_train.shape[0])\n",
        "print(\"Size of each image in dataset = \",x_train.shape[1:])\n",
        "print(\"No. of test examples = \",x_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX9xW4ardXZG"
      },
      "outputs": [],
      "source": [
        "# Run this cell to visualize some of the images from dataset\n",
        "\n",
        "n = 5    # = no. of images to visualize\n",
        "\n",
        "index = np.random.choice(x_train.shape[0],5)  # choose random index\n",
        "print(\"label: \",end=\"\")\n",
        "\n",
        "for i,ind in enumerate(index):\n",
        "    plt.subplot(1,n,i+1)\n",
        "    plt.imshow(x_train[ind],cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    print(y_train[ind],end=\"       \")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQcA9i9YdXZH"
      },
      "source": [
        "#### Preprocess dataset\n",
        "Since we are building a MLP model the input to the model should be a vector rather than a 28 by 28 matrix.\n",
        "\n",
        "So your **First Task** is to flatten the images\n",
        "\n",
        "(Hint: use *reshape()* method of arrays...)\n",
        "\n",
        "Next, create validation dataset out of training dataset.\n",
        "\n",
        "You can use 50K images for training and 10K for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXnkfE6gdXZI"
      },
      "outputs": [],
      "source": [
        "# Flatten the images into 1-d vectors\n",
        "\n",
        "x_train_flatten = ...                                       # flatten the images of training set\n",
        "x_test_flatten = ...                                        # flatten th eimages of test set\n",
        "\n",
        "\n",
        "# Divide the training data into training and validation data....\n",
        "\n",
        "n_validation = 10000                                        # choose number of images to be used for validation\n",
        "\n",
        "x_validation = ...\n",
        "y_validation = ...\n",
        "\n",
        "x_train_flatten = ...\n",
        "y_train = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMGl2aq3dXZJ"
      },
      "source": [
        "### **Build a model**\n",
        "You can choose whatever architechure you want, but ensure that it is **not too deep** as that will take too much time to train and **not too shallow** as that will give very low accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7yr3nwTdXZK"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    ...\n",
        "])\n",
        "\n",
        "# Make a graphical representation of the model...\n",
        "keras.utils.plot_model(model,show_shapes=True)\n",
        "model.summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oDNvKB6dXZL"
      },
      "source": [
        "#### Compile and Train\n",
        "Choose an optimizer- method that minimizes loss function\n",
        "\n",
        "**adam** optimizer is one of the popular choices. You should read about these online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DM9i_F5dXZL"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"...\",loss = \"...\",metrics=[\"accuracy\"])\n",
        "\n",
        "n_epochs = ...              # set number of epochs\n",
        "batch_size = 512            # you can tweak with these parametrs\n",
        "history = model.fit(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QTWTtoVdXZM"
      },
      "source": [
        "### **Evaluate**\n",
        "Evaluate your model on test data.\n",
        "\n",
        "And Show some results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhuBGWg-dXZM"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(...)\n",
        "print(\"Loss = \",results[0])\n",
        "print(\"Accuracy = \",results[1]*100,\"%\")\n",
        "\n",
        "# Plot Accuracy...\n",
        "plt.plot(..., label=\"Training accuracy\")\n",
        "plt.plot(..., label=\"validation Accuracy\")\n",
        "plt.title(\"Model accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Similarly write code to plot loss...\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hjr0CBhdXZN"
      },
      "source": [
        "Lets show our results on images from testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEs1cVAHdXZN"
      },
      "outputs": [],
      "source": [
        "n = ...   # = no. of images to see predictions on\n",
        "\n",
        "index = np.random.choice(...)  # choose random index from test data\n",
        "print(\"label: \")\n",
        "\n",
        "for i,ind in enumerate(index):\n",
        "    plt.subplot(1,n,i+1)\n",
        "    plt.imshow(...)             # fill code to show images from test set\n",
        "    plt.axis(\"off\")\n",
        "    print(y_test[ind],end=\"       \")\n",
        "\n",
        "plt.show()\n",
        "print(\"Predicted value: \")\n",
        "\n",
        "# Now lets print the predictions\n",
        "\n",
        "for i,ind in enumerate(index):\n",
        "    # write code to predict and print digit in image\n",
        "    # Hint: the output of the model is a 10-d vector which gives probabilties\n",
        "    # The digit in the image would be the class for which probability is hghest...\n",
        "\n",
        "    digit = ...\n",
        "    print(digit,end=\"      \")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}